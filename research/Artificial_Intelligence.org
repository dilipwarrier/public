#+TITLE: Interesting facts/news in AI
#+FILETAGS: :AI:

* My learnings with AI agents

Coursera specialization: [[https://www.coursera.org/specializations/build-genai-applications-and-agents][Building GenAI applications and agents]]

Reached [[https://www.coursera.org/learn/implementation-of-genai-agents/supplement/2RDEr/hands-on-learning-hol-implementing-core-ai-agent-functionalities][here]].

** TODO [#A] Work on Coursera specialization on [[https://www.coursera.org/specializations/build-genai-applications-and-agents][Building GenAI applications and agents]] :Learning:
SCHEDULED: <2026-01-07 Wed +1d>
:PROPERTIES:
:EFFORT:  10:00
:BENEFIT: 5000
:COST: 200
:VALUE:    3800.00
:PRIORITY_NUM: 5
:LAST_REPEAT: [2026-01-09 Fri 10:13]
:END:
- State "DONE"       from "TODO"       [2026-01-09 Fri 10:13]
- State "DONE"       from "TODO"       [2026-01-06 Tue 09:33]
:LOGBOOK:
CLOCK: [2026-01-09 Fri 07:58]--[2026-01-09 Fri 09:53] =>  1:55
CLOCK: [2026-01-09 Fri 06:29]--[2026-01-09 Fri 07:02] =>  0:33
CLOCK: [2026-01-06 Tue 06:27]--[2026-01-06 Tue 09:33] =>  3:06
CLOCK: [2026-01-05 Mon 06:34]--[2026-01-05 Mon 08:34] =>  2:00
CLOCK: [2026-01-03 Sat 21:19]--[2026-01-03 Sat 22:19] =>  1:00
CLOCK: [2026-01-02 Fri 07:35]--[2026-01-02 Fri 09:35] =>  2:00
:END:

** Mon 01/05

I started experimenting with AI agents and crewAI.

In my first attempt, I asked ChatGPT to create the source code within
the crewAI framework. ChatGPT created code but I got errors running
it - first docstring violations and then errors in a Python package
pydantic that I had to install as part of the requirements. I scrapped
this and restarted the process.

I followed the instructions for a first project on the crewAI web
site. That worked.

** Fri 01/02

Created an OpenAI API call. Saved the resulting simple script in
[[id:5e560df9-79b2-4600-95ee-f238c4bcae7d][OpenAI API key]].

* OpenAI API

** Installation

See [[id:5e560df9-79b2-4600-95ee-f238c4bcae7d][OpenAI installation]]

** Controlling randomness

The input parameter "temperature" controls how adventurous the model is
when selecting tokens. Lower values (around 0–0.3) make output more
deterministic and consistent while higher values (around 0.7–1.3)
increase creativity and variability.

The parameter top_p, or nucleus sampling, limits choices to the
smallest set of likely tokens whose cumulative probability is less
than or equal to p.

In practice, you would adjust only one parameter at a time: use
temperature for simpler control, and top_p when you want
probability-based filtering of token choices.

* Types of AI agents                                                 :Review:

** Simple reflex agents

Simple reflex agents act solely on the current percept, using
condition–action rules. They do not maintain internal state or memory
of past events. These agents work well only in fully observable,
simple environments.

Example: A thermostat that turns the heater on when temperature drops
below a threshold.

** Model-based agents

Model-based agents maintain an internal representation of the
world. They use this model to track how the environment evolves over
time. This allows them to handle partially observable environments.

Example: A robot vacuum that remembers which rooms it has already cleaned.

** Goal-based agents

Goal-based agents choose actions based on how well they help achieve a
specific goal. They evaluate future states and plan sequences of
actions. This enables flexible behavior beyond simple reactions.

Example: A navigation system planning a route to reach a destination.

** Utility-based agents

Utility-based agents evaluate actions by assigning a numeric utility
to outcomes. They choose actions that maximize expected utility, not
just goal achievement. This allows trade-offs between competing
objectives.

Example: A self-driving car balancing speed, safety, and passenger
comfort.

** Learning agents

Learning agents improve their performance over time based on
experience. They adapt by updating their knowledge, rules, or
models. This allows them to operate effectively in changing or unknown
environments.

Example: A recommendation system that improves suggestions based on
user feedback.

** Planning agents

Planning agents explicitly generate and evaluate sequences of actions
before acting. They rely on models of state transitions and often
use search or optimization algorithms. This makes them well-suited for
tasks requiring foresight and coordination.

Example: A warehouse robot planning pick-and-place actions to minimize
total travel time.

** References

- [[https://aima.cs.berkeley.edu][Artificial Intelligence: A Modern Approach (Russell & Norvig) – foundational text on AI agents]]
- [[https://www.ibm.com/topics/artificial-intelligence][IBM overview of artificial intelligence concepts and agent types]]
- [[https://www.geeksforgeeks.org/intelligent-agents-in-artificial-intelligence/][GeeksforGeeks article on intelligent agents with examples]]

* Characteristics of AI agent design                                 :Review:

To design a good AI agent, one should consider the following
properties.

** Role focus

It is usually best to focus the role of an AI agent e.g. a role could
be a "board-certified endocrinologist with decades of clinical and
surgical experience" when you are searching for medical advice related
to diabetes.

** Tools

An agent should only have access to tools that it needs to complete the
job. This makes the design of the agent efficient.

** Co-operation

Multiple discrete agents collaborating with each other can work more
efficiently than one large agent with multiple tools. A design may
consist of one agent planning the work to complete a task and then
distributing that work to other agents.

** Guardrails

An agent can get stuck in a loop trying a tool multiple
times. Guardrails ensure that the agent gets out of such endless
loops.

** Memory

In addition to task-specific memory, agents can also maintain
long-term memory. This ensures that the quality of the agent's work
improves over time.

* Generative AI                                                      :Review:

GPT = Generative Pretrained Transformer

It takes a string of words and rolls a die to predict the next
word. It does this sequentially until a stopping condition is met.

GPT-3 was generated using nearly 500B tokens of data. A token is
roughly a word.

GPT-3 has nearly 175B parameters.

This [[https://drive.google.com/file/d/1P0chJKuHdGFL_Pshl6l0wyqMJ4Gu_KQV/view?usp=drivesdk][article]] describes details of how GPT works.

GPT-3 was trained on several sources of data, but the bulk of it comes
from snapshots of the entire internet between 2016 and 2019 taken from
a database called Common Crawl. There's a lot of junk text on the
internet, so the initial 45 terabytes were filtered using a different
machine-learning model to select just the high-quality text: 570
gigabytes of it, a dataset that could fit on a modern laptop. In
addition, GPT-4 was trained on an unknown quantity of images, probably
several terabytes.

The inputs of LLMs — data, computing power, electricity, and skilled
labour — cost money. Training GPT-3, for example, used 1.3
gigawatt-hours of electricity (enough to power 121 homes in America
for a year), and cost OpenAI an estimated $4.6M. GPT-4, which is a
much larger model, will have cost disproportionately more (in the
realm of $100M) to train.
