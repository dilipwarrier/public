#+TITLE: Interesting facts/news in AI
#+FILETAGS: :AI:

* My learnings with AI agents

Coursera specialization: [[https://www.coursera.org/specializations/build-genai-applications-and-agents][Building GenAI applications and agents]]

Reached [[https://www.coursera.org/learn/implementation-of-genai-agents/supplement/2RDEr/hands-on-learning-hol-implementing-core-ai-agent-functionalities][here]].

** TODO [#A] Work on Coursera specialization on [[https://www.coursera.org/specializations/build-genai-applications-and-agents][Building GenAI applications and agents]] :Learning:
SCHEDULED: <2026-01-21 Wed +1d>
:PROPERTIES:
:EFFORT:  10:00
:BENEFIT: 5000
:COST: 200
:VALUE:    3800.00
:PRIORITY_NUM: 5
:LAST_REPEAT: [2026-01-20 Tue 10:34]
:END:
- State "DONE"       from "TODO"       [2026-01-20 Tue 10:34]
- State "DONE"       from "TODO"       [2026-01-09 Fri 10:13]
- State "DONE"       from "TODO"       [2026-01-06 Tue 09:33]
:LOGBOOK:
CLOCK: [2026-01-20 Tue 09:01]--[2026-01-20 Tue 10:33] =>  1:32
CLOCK: [2026-01-20 Tue 06:31]--[2026-01-20 Tue 08:01] =>  1:30
CLOCK: [2026-01-09 Fri 07:58]--[2026-01-09 Fri 09:53] =>  1:55
CLOCK: [2026-01-09 Fri 06:29]--[2026-01-09 Fri 07:02] =>  0:33
CLOCK: [2026-01-06 Tue 06:27]--[2026-01-06 Tue 09:33] =>  3:06
CLOCK: [2026-01-05 Mon 06:34]--[2026-01-05 Mon 08:34] =>  2:00
CLOCK: [2026-01-03 Sat 21:19]--[2026-01-03 Sat 22:19] =>  1:00
CLOCK: [2026-01-02 Fri 07:35]--[2026-01-02 Fri 09:35] =>  2:00
:END:

** Mon 01/05

I started experimenting with AI agents and crewAI.

In my first attempt, I asked ChatGPT to create the source code within
the crewAI framework. ChatGPT created code but I got errors running
it - first docstring violations and then errors in a Python package
pydantic that I had to install as part of the requirements. I scrapped
this and restarted the process.

I followed the instructions for a first project on the crewAI web
site. That worked.

** Fri 01/02

Created an OpenAI API call. Saved the resulting simple script in
[[id:5e560df9-79b2-4600-95ee-f238c4bcae7d][OpenAI API key]].

* OpenAI API

** Installation

See [[id:5e560df9-79b2-4600-95ee-f238c4bcae7d][OpenAI installation]]

** Controlling randomness

The input parameter "temperature" controls how adventurous the model is
when selecting tokens. Lower values (around 0–0.3) make output more
deterministic and consistent while higher values (around 0.7–1.3)
increase creativity and variability.

The parameter top_p, or nucleus sampling, limits choices to the
smallest set of likely tokens whose cumulative probability is less
than or equal to p.

In practice, you would adjust only one parameter at a time: use
temperature for simpler control, and top_p when you want
probability-based filtering of token choices.

* Langchain

All my langchain agent projects are stored in GitHub.

** TODO Create new GitHub repository for langchain-agents          :Learning:
SCHEDULED: <2026-01-21 Wed>

* Types of agents                                                 :Review:

** Simple reflex agents

Simple reflex agents act solely on the current percept, using
condition–action rules. They do not maintain internal state or memory
of past events. These agents work well only in fully observable,
simple environments.

Example: A thermostat that turns the heater on when the temperature drops
below a threshold.

** Model-based agents

Model-based agents maintain an internal representation of the
world. They use this model to track how the environment evolves over
time. This allows them to handle partially observable environments.

Example: A robot vacuum that remembers which rooms it has already cleaned.

** Goal-based agents

Goal-based agents choose actions based on how well they help achieve a
specific goal. They evaluate future states and plan sequences of
actions. This enables flexible behavior beyond simple reactions.

Example: A navigation system planning a route to reach a destination.

** Utility-based agents

Utility-based agents evaluate actions by assigning a numeric utility
to outcomes. They choose actions that maximize expected utility, not
just goal achievement. This allows trade-offs between competing
objectives.

Example: A self-driving car balancing speed, safety, and passenger
comfort.

** Learning agents

Learning agents improve their performance over time based on
experience. They adapt by updating their knowledge, rules, or
models. This allows them to operate effectively in changing or unknown
environments.

Example: A recommendation system that improves suggestions based on
user feedback.

** Planning agents

Planning agents explicitly generate and evaluate sequences of actions
before acting. They rely on models of state transitions and often
use search or optimization algorithms. This makes them well-suited for
tasks requiring foresight and coordination.

Example: A warehouse robot planning pick-and-place actions to minimize
total travel time.

** References

- [[https://aima.cs.berkeley.edu][Artificial Intelligence: A Modern Approach (Russell & Norvig) – foundational text on AI agents]]
- [[https://www.ibm.com/topics/artificial-intelligence][IBM overview of artificial intelligence concepts and agent types]]
- [[https://www.geeksforgeeks.org/intelligent-agents-in-artificial-intelligence/][GeeksforGeeks article on intelligent agents with examples]]

* Characteristics of AI agent design                                 :Review:

To design a good AI agent, one should consider the following
properties.

** Role focus

It is usually best to focus the role of an AI agent e.g. a role could
be a "board-certified endocrinologist with decades of clinical and
surgical experience" when you are searching for medical advice related
to diabetes.

** Tools

An agent should only have access to tools that it needs to complete the
job. This makes the design of the agent efficient.

** Co-operation

Multiple discrete agents collaborating with each other can work more
efficiently than one large agent with multiple tools. A design may
consist of one agent planning the work to complete a task and then
distributing that work to other agents.

** Guardrails

An agent can get stuck in a loop trying a tool multiple
times. Guardrails ensure that the agent gets out of such endless
loops.

** Memory

In addition to task-specific memory, agents can also maintain
long-term memory. This ensures that the quality of the agent's work
improves over time.

* Llama

What are the set of arithmetic operations that an LLM uses to convert
a string of input text into output?

For the open-source model Llama3, the answer lies in the files
[[https://github.com/meta-llama/llama-models/blob/main/models/llama3/model.py][model.py]] and [[https://github.com/meta-llama/llama-models/blob/main/models/llama3/generation.py][generation.py]].

model.py describes the model including the Attention, FeedForward, and
TransformerBlock classes.

How do Prefill and Decode map to these?

generation.py describes the generate(), chat_complete(),
etc. methods. Those use the methods and classes described in model.py.

[[https://github.com/meta-llama/llama-models/blob/main/models/llama3/scripts/chat_completion.py][chat_completion.py]] and [[https://github.com/meta-llama/llama-models/blob/main/models/llama3/scripts/completion.py][completion.py]] have example usage.

* Running open-source LLM models

Install [[https://ollama.com/download][Ollama]] on your PC.

Run the following.

#+begin_src shell
  # Note that this is the 8B model (5 GB file size)
  ollama pull llama3

  # Run a quick test to ensure it's working
  ollama run llama3 "Confirming system check: What is your model name?"
#+end_src

** Comparison of vLLM vs Ollama

|--------------+--------------------------------+----------------------------------|
| Feature      | Ollama                         | vLLM                             |
|--------------+--------------------------------+----------------------------------|
| Core Tech    | GGUF / llama.cpp               | PagedAttention / PyTorch         |
| Primary Goal | Ease of use & Local Desktop    | High Throughput & Serving        |
| Optimization | CPU (AVX2/512) & Apple Silicon | NVIDIA/AMD GPU (VRAM management) |
| Memory Mgmt  | Static KV Cache                | Dynamic Virtual Paging           |
| Best For     | Single-user, Private Chat      | Multi-user, API Scaling          |
|--------------+--------------------------------+----------------------------------|

Ollama allocates memory for context in large contiguous
blocks. This can lead to internal memory fragmentation. vLLM uses
virtual memory paging for the KV Cache. Blocks are mapped as needed,
allowing for near 100% VRAM utilization and massive batching.

For local prototyping, we recommend Ollama. It is lightweight and
handles the GGUF format which runs efficiently on standard
workstation RAM. For production, we recommend vLLM. It is the
industry standard for high-concurrency environments where
tokens-per-second-per-dollar must be minimized.

** Archive                                                          :ARCHIVE:
*** DONE Research and install Ollama                               :Learning:
SCHEDULED: <2026-01-23 Fri>
:PROPERTIES:
:ARCHIVE_TIME: 2026-01-25 Sun 20:20
:END:
- State "DONE"       from "TODO"       [2026-01-23 Fri 08:59]
:LOGBOOK:
CLOCK: [2026-01-23 Fri 08:09]--[2026-01-23 Fri 08:59] =>  0:50
:END:

* Evaluating performance of AI models

[[https://www.dennis-whalen.com/post/ai/promptfoo/promptfoo-1-testing-custom-llm-prompts/][Testing LLMs with promptfoo]]

Code and installation instructions are in the [[https://github.com/dilipwarrier/eval_ai][eval_ai GitHub]] repository.

** DeepEval

[[https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation][LLM and AI agent evaluation]]

I failed with DeepEval because it requires a company email address to
access the API. That discourages individual software engineers.

** Archive                                                          :ARCHIVE:
*** DONE Download tool for AI evaluation                           :Learning:
SCHEDULED: <2026-01-26 Mon>
:PROPERTIES:
:ARCHIVE_TIME: 2026-02-01 Sun 21:01
:END:
- State "DONE"       from "TODO"       [2026-01-26 Mon 08:42]
:LOGBOOK:
CLOCK: [2026-01-26 Mon 09:14]--[2026-01-26 Mon 10:34] =>  1:20
CLOCK: [2026-01-26 Mon 07:02]--[2026-01-26 Mon 08:42] =>  1:40
:END:

* AI as an architect

This note summarizes the debate regarding the shift from task-specific neural networks to
Large Language Model (LLM) centric architectures. The core of the discussion explores
whether LLMs, with increasing context windows and reasoning capabilities, have rendered
the "pre-LLM" method of training small, task-specific models obsolete.

The following table summarizes the three major eras of AI model development:

|----------------+-----------------------+-----------------------------+---------------------------------|
| Feature        | Pre-LLM (The Scalpel) | Post-LLM (Swiss Army Knife) | Agentic/Architect (The Foreman) |
|----------------+-----------------------+-----------------------------+---------------------------------|
| Primary Effort | Feature Engineering   | Prompt Engineering          | System Design & Verification    |
| Logic Storage  | Fixed Model Weights   | In-Context Memory           | Dynamic Programmatic Logic      |
| Execution      | Numerical Tensors     | Probabilistic Prediction    | Deterministic Computing         |
| Precision      | Very High             | Variable (Probabilistic)    | Very High                       |
| Flexibility    | Task-Specific         | General Purpose             | Adaptive & Self-Correcting      |
|----------------+-----------------------+-----------------------------+---------------------------------|

** The Case for "One Model to Rule Them All"

In the post-LLM world, developers can use "In-Context Learning" (ICL) to solve problems
that previously required bespoke models. By feeding training data directly into the
prompt, the model's attention mechanism performs a real-time synthesis of the task,
removing the need for separate training cycles.

** The Context Window Constraint

A major historical barrier to the LLM-only approach was the context window limit.
However, technology is rapidly expanding these windows (e.g., 128k to 1M+ tokens).
Combined with semantic compression of data records, it is increasingly feasible to
perform "training" purely within the inference prompt.

** The "Architect" Paradigm (The Foreman)

The most robust modern approach is using the LLM as an orchestrator rather than a
calculator. In this "Agentic" model:
- The LLM analyzes the data.
- It determines the best deterministic tool (e.g., a specific regression algorithm).
- It generates and executes the code to build that tool.
- This maintains mathematical precision while retaining LLM flexibility.

** Conclusions

While the "Scalpel" (bespoke models) still offers the lowest latency and highest
efficiency for fixed tasks, the "Foreman" approach is becoming the standard for
complex, evolving software engineering tasks where the human effort of manual
model-building is the primary bottleneck.

* Generative AI

GPT = Generative Pretrained Transformer

It takes a string of words and rolls a die to predict the next
word. It does this sequentially until a stopping condition is met.

GPT-3 was generated using nearly 500B tokens of data. A token is
roughly a word.

GPT-3 has nearly 175B parameters.

This [[https://drive.google.com/file/d/1P0chJKuHdGFL_Pshl6l0wyqMJ4Gu_KQV/view?usp=drivesdk][article]] describes details of how GPT works.

GPT-3 was trained on several sources of data, but the bulk of it comes
from snapshots of the entire internet between 2016 and 2019 taken from
a database called Common Crawl. There's a lot of junk text on the
internet, so the initial 45 terabytes were filtered using a different
machine-learning model to select just the high-quality text: 570
gigabytes of it, a dataset that could fit on a modern laptop. In
addition, GPT-4 was trained on an unknown quantity of images, probably
several terabytes.

The inputs of LLMs — data, computing power, electricity, and skilled
labour — cost money. Training GPT-3, for example, used 1.3
gigawatt-hours of electricity (enough to power 121 homes in America
for a year), and cost OpenAI an estimated $4.6M.

GPT-4, which is a much larger model, will have cost disproportionately
more (in the realm of $100M) to train.
